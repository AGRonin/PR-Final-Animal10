import torch
import clip
import os
from torch import nn
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from pathlib import Path
import pandas as pd
from PIL import Image
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# è‡ªåŠ¨æ£€æµ‹è®¡ç®—è®¾å¤‡
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"å½“å‰ä½¿ç”¨çš„è®¡ç®—è®¾å¤‡: {DEVICE}")


# æ•°æ®å¯¼å…¥ç±»è®¾è®¡
class AnimalsDataset(Dataset):
    def __init__(self, root: str, split: str, transform: transforms.Compose = None):
        """
        root: æ•°æ®é›†æ ¹ç›®å½•
        split: 'train', 'val', æˆ– 'test'
        transform: å›¾åƒé¢„å¤„ç†æµæ°´çº¿
        """
        self.root = Path(root)
        self.split = split
        self.transform = transform

        # è¯»å– CSV åˆ†å‰²æ–‡ä»¶
        df = pd.read_csv(self.root / "train_test_val_split.csv")
        df["path"] = df["path"].astype(str)

        # å®šä¹‰ç±»åˆ«æ˜ å°„
        self.classes = ["dog", "horse", "elephant", "butterfly",
                        "chicken", "cat", "cow", "sheep", "spider", "squirrel"]
        self.classes_to_idx = {c: i for i, c in enumerate(self.classes)}

        # ç­›é€‰å¯¹åº”çš„æ•°æ®é›† (train/val/test)
        df = df[df["split"] == self.split].reset_index(drop=True)
        #====== å­é‡‡æ ·ï¼šæ¯ä¸ªç±»åˆ«æœ€å¤šå– N å¼ ï¼ˆä»…ç”¨äºè®­ç»ƒé›†ï¼‰ ======
        if self.split == "train":
            max_per_class = 500   

            df = (
                df.groupby("label", group_keys=False)
                  .apply(lambda x: x.sample(
                      n=min(len(x), max_per_class),
                      random_state=42
                  ))
                  .reset_index(drop=True)
        )
        self.paths = [self.root / p for p in df["path"].tolist()]
        self.labels = [self.classes_to_idx[c] for c in df["label"].tolist()]

    def __len__(self):
        return len(self.paths)

    def __getitem__(self, idx):
        path = self.paths[idx]
        y = self.labels[idx]
        # å¿…é¡»è½¬ä¸º RGBï¼Œå› ä¸ºæˆ‘ä»¬çš„éƒ¨åˆ†è¾“å…¥å›¾ç‰‡æ˜¯RGBAçš„pngæ ¼å¼ï¼Œç›´æ¥è¯»å–ä¼šæœ‰å››ä¸ªé€šé“
        img = Image.open(path).convert("RGB")

        if self.transform:
            img = self.transform(img)

        return img, torch.tensor(y, dtype=torch.long)


# æ•°æ®å¯¼å…¥å‡½æ•°
def data_load(root):
    train_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),  # æ°´å¹³ç¿»è½¬æ•°æ®å¢å¼º
        transforms.ToTensor(),  # è½¬ä¸º Tensor å¹¶å½’ä¸€åŒ–è‡³ [0, 1]
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # éªŒè¯/æµ‹è¯•é›†é¢„å¤„ç†ï¼šä¸¥è°¨èµ·è§ï¼Œä¸åšéšæœºå¢å¼ºï¼Œä»…åšæ ‡å‡†åŒ–
    val_test_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    batch_size=128

    train_dataset = AnimalsDataset(root=root, split="train", transform=train_transform)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

    val_dataset = AnimalsDataset(root=root, split="val", transform=val_test_transform)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

    test_dataset = AnimalsDataset(root=root, split="test", transform=val_test_transform)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    data_class = {
        "train_dataset": train_dataset,
        "train_loader": train_loader,
        "val_dataset": val_dataset,
        "val_loader": val_loader,
        "test_dataset": test_dataset,
        "test_loader": test_loader
    }
    return data_class


class CLIPClassifier(nn.Module):
    def __init__(self, num_classes):
        super(CLIPClassifier, self).__init__()

        # åŠ è½½ CLIP
        self.clip_model, _ = clip.load("ViT-B/32", device=DEVICE)

        # å†»ç»“å…¨éƒ¨å‚æ•°
        for param in self.clip_model.parameters():
            param.requires_grad = False

        # ğŸ‘‰ åªè§£å†» visual çš„æœ€åä¸€ä¸ª transformer blockï¼ˆéå¸¸è½»é‡ï¼‰
        for param in self.clip_model.visual.transformer.resblocks[-1].parameters():
            param.requires_grad = True

        # åˆ†ç±»å¤´
        self.classifier = nn.Linear(512, num_classes)

    def forward(self, x):
        # ä¸å†ä½¿ç”¨ no_gradï¼ˆå› ä¸ºæˆ‘ä»¬è§£å†»äº†æœ€åä¸€å±‚ï¼‰
        image_features = self.clip_model.encode_image(x)

        logits = self.classifier(image_features)
        return logits


# å‡†ç¡®ç‡è¯„ä¼°
def evaluate(model, dataloader):
    model.eval()
    correct_count = 0
    total_count = 0
    with torch.no_grad():
        for images, labels in dataloader:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            logits = model(images)
            predicted = logits.argmax(dim=1)
            total_count += labels.numel()
            correct_count += (predicted == labels).sum().item()
    return correct_count / total_count


def draw_train_plot(list_train_acc, list_val_acc, list_train_loss):
    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    plt.plot(range(1, len(list_train_loss) + 1), list_train_loss, label='Train Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(range(1, len(list_train_acc) + 1), list_train_acc, label='Train Accuracy')
    plt.plot(range(1, len(list_val_acc) + 1), list_val_acc, label='Val Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.savefig('output/training_curves.png')
    plt.show()


# éªŒè¯è¿‡ç¨‹
def verify_net(model, val_loader):
    acc = evaluate(model, val_loader)
    print(f"éªŒè¯é›†å‡†ç¡®ç‡ä¸º{acc}")
    return acc


# è®­ç»ƒè¿‡ç¨‹
def train_net(model, lr, num_epochs, train_loader, val_loader):
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
    list_train_loss = []
    list_train_acc = []
    list_val_acc = []
    last_val_acc = 0
    for epoch in range(num_epochs):
        # è®­ç»ƒè¿‡ç¨‹
        model.train()
        total_loss = 0.0
        for images, labels in train_loader:
            # å‰å‘ä¼ æ’­
            logits = model(images)
            # è¯¯å·®è®¡ç®—
            loss = criterion(logits, labels)
            # åå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–°
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f'ç¬¬{epoch + 1}æ¬¡å¾ªç¯:')

        # è®­ç»ƒæŸå¤±ç»Ÿè®¡
        avg_loss = total_loss / len(train_loader)
        list_train_loss.append(avg_loss)
        print(f"\tè®­ç»ƒå¹³å‡lossä¸º{avg_loss}")

        # è®­ç»ƒå‡†ç¡®ç‡ç»Ÿè®¡
        train_acc = evaluate(model, train_loader)
        list_train_acc.append(train_acc)
        print(f'\tè®­ç»ƒæ­£ç¡®ç‡ä¸º{train_acc}')

        # éªŒè¯å‡†ç¡®ç‡ç»Ÿè®¡+é‡‡ç”¨æœ€ç®€å•çš„æ—©åœæœºåˆ¶æ§åˆ¶è¿‡æ‹Ÿåˆ
        verify_acc = verify_net(model, val_loader)
        if last_val_acc > verify_acc:
            break
        else:
            last_val_acc = verify_acc
            list_val_acc.append(verify_acc)

    return model, list_train_acc, list_val_acc, list_train_loss


# ç»˜åˆ¶æ··æ·†çŸ©é˜µ
def plot_confusion_matrix(model, test_loader, class_names):
    model.eval()
    all_preds = []
    all_labels = []
    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)
            outputs = model(inputs)
            _, predicted = torch.max(outputs, 1)
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    cm = confusion_matrix(all_labels, all_preds)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
    disp.plot(cmap=plt.cm.Blues)
    plt.title("Confusion Matrix")
    plt.savefig("output/confusion_matrix.png")
    plt.show()


# æµ‹è¯•
def test_net(model, test_loader, test_dataset):
    acc = evaluate(model, test_loader)
    print(f"æµ‹è¯•é›†å‡†ç¡®ç‡ä¸º{acc}")
    plot_confusion_matrix(model, test_loader, class_names=test_dataset.classes)


def main():
    # æ•°æ®å¯¼å…¥
    print("æ•°æ®å¼€å§‹å¯¼å…¥ã€‚ã€‚ã€‚")
    data_class = data_load(r"D:\bnu-å¤§å­¦\ç–¯ç‹‚çš„å¤§ä¸‰\æ¨¡å¼è¯†åˆ«\å®éªŒä½œä¸š\å¤§ä½œä¸š\Animals-10\Animals-10")
    train_loader = data_class["train_loader"]
    test_dataset = data_class["test_dataset"]
    val_loader = data_class["val_loader"]
    test_loader = data_class["test_loader"]
    print("æ•°æ®å¯¼å…¥æˆåŠŸï¼\n")

    # æ¨¡å‹
    num_classes = 10
    model = CLIPClassifier(num_classes).to(DEVICE)

    # è®­ç»ƒ+éªŒè¯
    print("è®­ç»ƒå¼€å§‹ã€‚ã€‚ã€‚")
    # train_net(model, lr, num_epochs, train_loader, val_loader)
    # return model, list_train_acc, list_val_acc
    trained_model, list_train_acc, list_val_acc, list_train_loss = train_net(model, 1e-4, 2, train_loader, val_loader)
    print("è®­ç»ƒç»“æŸ!\n")

    # ç»˜å›¾
    # draw_train_plot(list_train_acc, list_val_acc, list_train_loss)
    draw_train_plot(list_train_acc, list_val_acc, list_train_loss)

    # æµ‹è¯•
    print("æµ‹è¯•å¼€å§‹ã€‚ã€‚ã€‚")
    # test_net(model, test_loader, test_dataset)
    test_net(trained_model, test_loader, test_dataset)
    print("æµ‹è¯•ç»“æŸï¼\n")
    return 0


if __name__ == "__main__":
    os.makedirs("output", exist_ok=True)
    main()
